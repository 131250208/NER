{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "config = yaml.load(open(\"ensemble_config.yaml\", \"r\"), Loader = yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = config[\"keyword\"]\n",
    "res_dir = config[\"res_dir\"]\n",
    "run_ids = config[\"run_ids\"]\n",
    "\n",
    "run_id2path_list = {}\n",
    "for run_id in run_ids:\n",
    "    path_pattern = os.path.join(res_dir, run_id, \"*{}*.json\".format(keyword))\n",
    "    if run_id not in run_id2path_list:\n",
    "        run_id2path_list[run_id] = []\n",
    "    for path in glob(path_pattern):\n",
    "        run_id2path_list[run_id].append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only last k\n",
    "k = config[\"last_k_res\"]\n",
    "for run_id, path_list in run_id2path_list.items():\n",
    "    run_id2path_list[run_id] = path_list[-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading res: 100%|██████████| 4/4 [00:02<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "res_total = []\n",
    "total_path_list = []\n",
    "for path_list in run_id2path_list.values():\n",
    "    total_path_list.extend(path_list)\n",
    "for path in tqdm(total_path_list, desc = \"loading res\"):\n",
    "    res_total.extend([json.loads(line) for line in open(path, \"r\", encoding = \"utf-8\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading into list: 100%|██████████| 19049/19049 [00:00<00:00, 28316.00it/s]\n"
     ]
    }
   ],
   "source": [
    "id_list, text_list, entity_list, tok_span_list, char_span_list, type_list = [], [], [], [], [], []\n",
    "for sample in tqdm(res_total, desc = \"loading into list\"):\n",
    "    for ent in sample[\"entity_list\"]:\n",
    "        id_list.append(sample[\"id\"])\n",
    "        text_list.append(sample[\"text\"])\n",
    "        entity_list.append(ent[\"text\"])\n",
    "        tok_span_list.append(\"{},{}\".format(*ent[\"tok_span\"]))\n",
    "        char_span_list.append(\"{},{}\".format(*ent[\"char_span\"]))\n",
    "        type_list.append(ent[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df = pd.DataFrame({\n",
    "    \"id\": id_list,\n",
    "    \"text\": text_list,\n",
    "    \"entity\": entity_list,\n",
    "    \"tok_span\": tok_span_list,\n",
    "    \"char_span\": char_span_list,\n",
    "    \"type\": type_list,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entity</th>\n",
       "      <th>tok_span</th>\n",
       "      <th>char_span</th>\n",
       "      <th>type</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9679</td>\n",
       "      <td>Shared and distinct genetic risk factors for c...</td>\n",
       "      <td>adult-onset asthma</td>\n",
       "      <td>13,19</td>\n",
       "      <td>65,83</td>\n",
       "      <td>Disease</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9679</td>\n",
       "      <td>Shared and distinct genetic risk factors for c...</td>\n",
       "      <td>adult-onset asthma</td>\n",
       "      <td>35,41</td>\n",
       "      <td>153,171</td>\n",
       "      <td>Disease</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9679</td>\n",
       "      <td>Shared and distinct genetic risk factors for c...</td>\n",
       "      <td>adult-onset asthma</td>\n",
       "      <td>73,79</td>\n",
       "      <td>332,350</td>\n",
       "      <td>Disease</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9679</td>\n",
       "      <td>Shared and distinct genetic risk factors for c...</td>\n",
       "      <td>asthma</td>\n",
       "      <td>128,131</td>\n",
       "      <td>582,588</td>\n",
       "      <td>Phenotype</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9679</td>\n",
       "      <td>Shared and distinct genetic risk factors for c...</td>\n",
       "      <td>asthma</td>\n",
       "      <td>16,19</td>\n",
       "      <td>77,83</td>\n",
       "      <td>Phenotype</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  \\\n",
       "0  9679  Shared and distinct genetic risk factors for c...   \n",
       "1  9679  Shared and distinct genetic risk factors for c...   \n",
       "2  9679  Shared and distinct genetic risk factors for c...   \n",
       "3  9679  Shared and distinct genetic risk factors for c...   \n",
       "4  9679  Shared and distinct genetic risk factors for c...   \n",
       "\n",
       "               entity tok_span char_span       type  num  \n",
       "0  adult-onset asthma    13,19     65,83    Disease    2  \n",
       "1  adult-onset asthma    35,41   153,171    Disease    3  \n",
       "2  adult-onset asthma    73,79   332,350    Disease    3  \n",
       "3              asthma  128,131   582,588  Phenotype    4  \n",
       "4              asthma    16,19     77,83  Phenotype    4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_df_w_duplicate_num = ensemble_df.groupby(ensemble_df.columns.tolist(), as_index = False).size().reset_index().rename(columns={0: 'num'})\n",
    "ensemble_df_w_duplicate_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32893\n"
     ]
    }
   ],
   "source": [
    "vote_threshold = config[\"vote_threshold\"]\n",
    "ensemble_res_df = ensemble_df_w_duplicate_num[ensemble_df_w_duplicate_num.num >= vote_threshold]\n",
    "print(len(ensemble_res_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32893/32893 [00:19<00:00, 1654.72it/s]\n",
      "100%|██████████| 4721/4721 [00:00<00:00, 197230.09it/s]\n"
     ]
    }
   ],
   "source": [
    "id2text, id2entities = {}, {}\n",
    "for idx in tqdm(range(len(ensemble_res_df))):\n",
    "    row = ensemble_res_df.iloc[idx]\n",
    "    id2text[row.id] = row.text\n",
    "    if row.id not in id2entities:\n",
    "        id2entities[row.id] = []\n",
    "\n",
    "    char_span = row.char_span.split(\",\")\n",
    "    tok_span = row.tok_span.split(\",\")\n",
    "    id2entities[row.id].append({\n",
    "        \"text\": row.entity,\n",
    "        \"char_span\": [int(char_span[0]), int(char_span[1])],\n",
    "        \"tok_span\": [int(tok_span[0]), int(tok_span[1])],\n",
    "        \"type\": row.type,\n",
    "    })\n",
    "\n",
    "emsemble_res = []\n",
    "for idx, text in tqdm(id2text.items()):\n",
    "    emsemble_res.append({\n",
    "        \"text\": text,\n",
    "        \"id\": int(idx),\n",
    "        \"entity_list\": id2entities[idx],\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4721/4721 [00:00<00:00, 13748.01it/s]\n"
     ]
    }
   ],
   "source": [
    "ensemble_res_dir = config[\"ensemble_res_dir\"]\n",
    "if not os.path.exists(ensemble_res_dir):\n",
    "    os.makedirs(ensemble_res_dir)\n",
    "    \n",
    "file_num = len(glob(os.path.join(ensemble_res_dir, \"*ensemble*.json\")))\n",
    "save_path = os.path.join(ensemble_res_dir, \"ensemble_res_{}.json\".format(file_num))\n",
    "\n",
    "with open(save_path, \"w\", encoding = \"utf-8\") as file_out:\n",
    "    for sample in tqdm(emsemble_res):\n",
    "        json_line = json.dumps(sample, ensure_ascii = False)\n",
    "        file_out.write(\"{}\\n\".format(json_line))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
