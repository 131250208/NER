experiment_name: en_ace04
run_name: cln_p+mrctp_bert

data_home: ../data/data4bert

train_data: train_data.json
valid_data: valid_data.json

meta: meta.json
type2questions: type2questions.json
 
device_num: 2

wandb: false
path_to_save_model: ../model_state

encoder: BERT
bert_path: /home/wangyucheng/opt/transformers_models_h5/bert-base-cased

hyper_parameters:
 batch_size: 32
 parallel: false
 epochs: 100
 lr: 5e-5
 seed: 2333
 log_interval: 10
 max_seq_len: 100
 pred_max_seq_len: 128
 sliding_len: 20
 pred_sliding_len: 20
 visual_field: -1 # -1: use recommended value
 pooling_type: mean
 shaking_type: cat_plus
 
 # CosineAnnealingWarmRestarts
 scheduler: CAWR # Step
 T_mult: 1
 rewarm_epoch_num: 4
 
#  # StepLR
#  scheduler: Step
#  decay_rate: 0.99
#  decay_steps: 100
 
# when to save the model state dict
f1_2_save: 0
# whether train from scratch
fr_scratch: true
# note 
note: start from scratch
# if not fr scratch, set a model_state_dict
model_state_dict_path: stake